\chapter{总结与展望}
\label{chap:chap05}

\section{全文总结}

随着互联网的高速发展和社交网络的持续增长，文本类型数据的量级呈现出爆炸式的增长，形式也变得越来越复杂和多样。文本类型数据中包含了大量的知识和有用信息，但因为文本类型数据的高度抽象化和形式多样化，自动的、准确的从文本数据中抽取有用信息变得更困难也更重要。人工智能的发展离不开知识的支撑，特别是从感知智能到认知智能的进化，必须具备大量的知识积累，才能具备知识推理的能力。散落在互联网上的文本信息中包含了大量的有价值的知识，我们需要一种更准确和高效的方法，从这些海量文本中抽取出有用信息，构建我们的知识图谱，来支撑人工智能的发展。本文主要研究信息抽取领域的一个重要的任务―― 文本记录分割与命名属性值识别取，即对一段语义丰富的半结构化文本首先按各属性的不同准确分割文本，然后给予每个文本段正确的标签。对于这种特殊的文本形式，因为其内部属性值之间没有关联，各属性值顺序不固定等根本原因，使得传统的方法的抽取质量不能够满足现实的要求，适应场景也受到限制。因此，本文提出了一种基于深度学习的贪婪式概率标注算法，并实现了一个自动训练和执行抽取的可视化系统，可以更方便的训练模型，更方便的移植到其他数据集，更方便的执行抽取任务， 并且可以更客观的观察我们提出的方法各步骤结果。本文的具体研究内容如下：

（1）对深度学习在文本上的应用做了讨论和分析，重点介绍了词嵌入技术，列举了深度学习在自然语言处理中若干个领域的解决思路。介绍了文本记录分割与命名属性值识别的概念，说明了文本记录分割与命名属性值识别的现实意义，深入研究了现有方法的解决思路，并对这些方法的优缺点做了详细的分析。

（2）提出了一种基于CNN的文本记录分割与命名属性值识别算法。对于传统方法中的匹配函数表现能力不足，应用场景受限等劣势，我们提出了一种适用场景更多，抽取质量更好的方法，即利用深度卷积神经网络强大的数据表征能力，并结合概率模型来构建我们的抽取模型，非常明显得提升了抽取质量。简要来讲，借助于事先构建的知识库，训练一个卷积神经网络分类模型（CNN分类模型），同时借助知识库做初始的分割，为了充分使用知识库，另外从知识库中求得了文本段在不同属性中与词频先关的信息，用来识别\emph{锚点块}，\emph{锚点块}在我们的模型中的具有非常重要的作用。对于我们的输入文本类型，各属性值虽然语法上独立，但是语义上存在着某种隐藏联系，本文提出的算法就有利用到这种结构相关的信息。尽管CNN分类模型能够直接给出文本段属于各属性的概率，但是这种标注方式只是单独的考虑了这一个文本段，没有综合考虑这个文本段与输入文本中其他文本段的关系，因此这种方法可能不能找到最佳的分割和标注方式，因此本文提出了一种\emph{贪婪式概率标注算法}，可以从全局考虑，找到最佳方案。我们的模型至此就已经可以取得非常好的抽取结果了，但是为了进一步修正错标注和漏标注的情形，本文又提出了一种\emph{双向位置与序列模型}，这个模型可以捕获关于某一领域数据集中属性值分布的一些规律，并从前向和后向两个不同的方向来刻画这种信息，我们的模型充分利用了这个重要的信息来进一步强化标注结果。

（3）对于上面的模型，本文详细介绍了构建CNN分类模型的各个细节，分析了一些超参的选择策略。另外，我们还开发了一个系统，用于更方便地训练模型、执行抽取任务并查看本文提出模型各步骤的中间结果，并在文章中详细介绍了这个系统的各个模块。


\section{工作展望}

本文对文本记录分割与命名属性值识别任务进行了研究，分析了传统方法的不足之处，提出了基于深度学习的贪婪式概率标注算法，通过与以往方法对比，在几个真实数据集上验证了本文提出算法的效果，实验结果表明，所提出的算法在抽取质量上取得了非常明显的提升，并且在抽取效率上也要优于其他算法。然后，其中仍有可以改进的地方：

（1）本文提出的基于CNN的算法中，分割与标注是分开进行的，使用知识库做分割，然后将分割的结果再使用CNN来处理，然后基于CNN分类模型的输出结果设计一系列概率相关的标注算法。之所以这样处理，是因为对于文本来说，一个单词，或者中文中的一个词语，粒度太大了，我们必须根据知识库先做一步分割。然而，图像中处理思路却不是这样的，在做图像的物体识别任务时，定位和分类是放在一个模型中做的，比如在经典的物体识别模型Fast R-CNN~\ucite{girshick2015fast} 中，除了提取proposal，它将CNN特征提取、物体分类、物体框的定位回归放在同一个网络中，实现了End-to-End的训练，这样会大大减少训练模型的时间，以及使用模型的时间，将分类和定位共同训练，从某种角度来说也能增加模型的精度。在我们提出的模型中，训练模型和执行抽取时各部分是隔离的，虽然我们提出了相关措施来避免独立考虑文本段，但这种模型仍然有很多弊端。因此，在我们的未来工作中，我们会考虑将文本段的定位与文本段的分类放在一个模型中，完全改变现有模型各步骤串行工作的方式，这会大大提高抽取效率。


（2）深度学习模型已经广泛的应用于自然语言处理的各个领域中，事实证明在一些领域深度学习模型非常适合。因此，我们将在未来的工作中，探索使用更多的深度学习模型来解决信息抽取任务，包括使用善于解决序列标注问题的LSTM，基于Attention机制的网络，对抗网络，强化学习等。另外，在构建CNN分类模型的输入矩阵时，本文使用了6 种特征（word2vec也算做了一种），我们可以继续探索更多的、更有效的特征加入到输入矩阵中。在序列化数据的建模中，比如用RNN，LSTM这样的循环神经网络虽然可以学习到潜在的数据间依赖，但是其表达力依然有限，越来越多的研究工作开始关注引入外部知识库或者额外信息来丰富当前数据的语义表达，从而辅助数据理解。因此，我们认为对知识库的使用还不够完全，我们将在未来的工作中，继续探索如何在建模时将更多的外部知识融入到模型之中。


（3）在我们的模型中有两处阈值的设定，一个是定义锚点块的 $\theta$，一个是控制低质量标注的$\lambda$，阈值的设定对模型的影响非常大。本文中提出的算法中所使用的两个阈值都是通过大量实验获得的，虽然我们在这三个数据集上得到了相同的阈值，但是目前还不能证明在所有的数据集上这个阈值也是适应的，我们还是认为阈值是对数据集敏感的。这就意味着，对于每个数据集我们都要通过做实验来找到最佳的阈值，这在实际应用中将是一个很繁琐的事情。对此，可以使用一些机器学习的方法或众包的方式去自动调整阈值。通过这些方法可以使算法更好的适应其它数据集，进而获得更好的抽取效果。

（4）在我们设计和开发的系统中，虽然有在线设定模型超参这一模块，但是目前还只是一个赋值的过程。对于每个数据集，我们需要先通过较粗粒度的网格搜索来确定一组CNN网络的超参。我们希望在后面的系统改进中加入超参的自动寻值模块。系统会使用网格搜索，在指定数据集上进行自动搜索，寻找到一组最合适的超参。且此系统目前还无法在线改变模型的网络结构，我们希望在后面的工作中，在模型初始化模块中加入更多功能，做到不仅可以在线赋予模型超参，也可以在线设计模型的网络结构，并可视化模型结构。

