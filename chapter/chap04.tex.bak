

\chapter{系统的实现与展示}

\section{CNN模型构建细节}
本文提出的基于深度卷积神经网络(CNN)的信息抽取模型，除了事先构建知识库和第一步做初始的文本分割，其他部分的执行都是基于我们构建的CNN分类模型的输出结果。因此，我们的分类器模型需要能更准确的刻画各属性值的区别，有更高的准确率。我们知道，卷积神经网络(CNN)的优势在于它能充分抽取特征和自由组合特征的能力，但是CNN模型的这个优势，从另一个角度来讲，恰恰也是它的一个劣势――缺乏模型解释性。因此，我们在使用卷积神经网络来构建深度学习模型时，更多时候我们只能把它看做黑盒子。但是，我们还是可以通过加入一些模型训练技巧，探索合适的超参数，改变模型结构来提高模型的表现力。在这一节，我们将详细介绍构建CNN分类模型的一些细节(本文将不再给出实验结果，我们会结合实验结果尝试解释如此选择的原因，从而得到一些经验相关的知识)：
\vspace{-2pt}
\begin{enumerate}[1)]\setlength{\itemsep}{-1pt}

  \item  \textit{CNN模型结构:} 我们使用了文章~\cite{kim2014convolutional}中类似的模型结构，在输入层之后，是一个多卷积核的卷积层，然后接一个池化层，最后是一个Softmax分类器。卷积层和池化层的层层叠加构成了卷积神经网络模型(有些模型没有池化层)，一般来讲，现实中常用的基于卷积神经网络的深度学习模型都会有很多层的卷积层加池化层，特别是在做图像和语音的任务中。因此，我们在构建自己的模型时，尝试增加卷积层和池化层的数量，但是通过实验我们发现，这并没有提升模型的表现力，反而有略微的相反作用，并且更重要的一点是，增加了层数，模型训练时间会有明显的增加。模型层数多就代表模型需要学习的参数更多，当我们要做图像识别时，模型的输入是图像的像素矩阵，这个矩阵的特征密度非常高，因此我们需要一层一层的，从低阶到高阶的，从部分到整体的对输入矩阵进行处理，并在每一层进行特征的抽象和组合。图像中特征的刻画是非常复杂的，比如从低阶的边角特征组合成不同动物是需要在非常高阶上组合的，因此，增加模型的层数，才能够用更多的参数来刻画这种高阶的特征。而在我们的应用场景中，首先因为我们的模型输入矩阵是训练好的word2vec，虽然是一种压缩的高密度文本表征方式，但是这种‘高密度’也是相对于one-hot编码而言，相比较图像的像素矩阵，所包含的特征密度还是差得很远，因此我们不需要这么深的网络。另外，我们训练CNN模型的输入是来自于知识库中的属性值，它的文本长度相对较短，即使最终将所有输入都归一化之后，也不会是很大的输入矩阵，这种输入矩阵的大小也不需要我们使用过深的网络。此外网络越复杂过拟合的可能性越大。因此，这种单层卷积加单层池化的结构是最适合我们的应用场景的。


  \item \textit{CNN模型通道:} CNN网络中的不同\emph{通道}可以解释为‘看’输入矩阵的不同角度，比如，在做图像识别时，我们有红，绿，蓝三个通道，模型在三个通道上同时运行，然后以某种方式组合起来。在我们的模型中，也采用了类似的模式。我们使用静态通道和动态通道，静态通道是指，对于我们的输入矩阵――word2vec，在训练我们的模型时此输入矩阵保持不变，而模型的其他参数随着模型训练而改变。动态通道是指，不仅模型的其他参数随着训练的过程而改变，输入的word2vec也会在训练过程中进行微调。具体来讲，在训练时，同时给模型两组训练数据，输入的都是词向量，然后在每一组训练数据上，每一组词向量就看做是一个通道，然后每个卷积核会同时在两组训练数据上执行，但是，梯度的反向传播只在其中一个通道上进行。这样就可以保持一个通道上输入词向量不变，也就是静态通道，而微调另一个通道的输入词向量，也就是动态通道。而静态通道和动态通道的实现在Tensorflow中也是比较简单，只需要在 $Variable$ 类中设置$trainable=True/False$，然后相应的改变后面步骤中张量的维度就行了。这种策略在文章~\cite{kim2014convolutional, zhang2015sensitivity} 中有详细的讨论。


  \item \textit{卷积核数量和大小:} 我们的输入是一句话，假设规则化之后，输入文本长度是 $d$ ，词向量的维度为 $V$，则输入矩阵便是一个 $d \times V$ 的矩阵，每行代表一个词语。类似于语言模型中的 $n-gram$ 思路，我们需要将相邻的若干个词语同时来考虑，也就是需要卷积核每次读入 $m$ 行词向量，这个行数就看做是卷积核的大小。当确定了卷积核的大小之后，不同参数的卷积核可以抽取出不同的特征，因此看做是不同的卷积核。我们通过随机设定卷积的参数，便可以得到若干个不同的卷积核，每个卷积核都能够抽取出一个特征图(future map)，最终会综合考虑所有得到的特征图。为了充分的抽取特征，在卷积层中，我们使用了不同大小的卷积核，并且每种大小的卷积核中设置一定数量的卷积核。在文章~\cite{zhang2015sensitivity} 中证明了，对于不同的数据集，卷积核数量和大小的选择是不同的，并且，当每个通道选择相同大小的卷积核往往可以取得更好的表现。因此，我们通过实验得出了对于我们的每个数据集来说，最合适的选择，如表~\ref{table:6} 所示，其中括号内表示两个通道各自的卷积核大小，斜线后面表示每个通道卷积核数量。其中卷积核大小的选择空间设定为：$[3,5,7,9,10,15,20,25]$，数量的选择空间设定为 $[50,100,200,300,400,500,600]$。


  \item \textit{卷积方式:} 卷积方式有两种，宽卷积(Wide convolution)和窄卷积(Narrow convolution)，这两种方式的主要区别就是对于输入矩阵边界值的处理策略不同。我们的模型中使用宽卷积，就是使用零填充(zero-padding)，这样就可以完全覆盖输入矩阵中所有的值，得到更大或者相同大小的输出特征图。


  \item \textit{激活函数:} 我们在不同的数据集上比较了几种激活函数方式，$Relu$ 和 $tanh$，特殊的，我们也测试了不使用激活函数($NoA$)时的表现，因为文章~\cite{zhang2015sensitivity} 中发现，在有些数据集中，不使用激活函数却得到了更好的结果。经过我们的试验发现，在引文数据集中，不使用激活函数取得了更好的实验结果。


  \item \textit{池化方式:} 在我们的模型中，池化层放在卷积层后面，池化的作用有两个，第一个作用是降低维度，第二个作用是统一输出形式。在我们的模型中，使用 $1-max \; Pooling$，也是比较通用和有效的一种 $Pooling$ 方式，在我们的模型汇总 $Pooling$ 窗口的大小就是输入文本的长度，这样每个卷积核最终的输出都是一个值。


  \item \textit{正则化:} 我们使用两种正则化策略，一个是 $dropout$ 正则，一个 $l2$ 正则。我们使用了文章~\cite{zhang2015sensitivity}中相同的办法来寻找最佳的值，通过实验，我们得到图~\ref{table:6}中的结果。其实，正则化对于模型的影响非常小，我们比较不同正则化值得区别也非常小。这可能是因为我们的模型只是一个较浅层的网络，模型复杂度不高，所以正则化的作用没有那么明显。同时，我们也尝试在我们的模型中加入 $batch \; normalization$ 的技巧 \cite{ioffe2015batch}，发现并不会对模型的表现起到明显的帮助，只是稍微缩减了一点模型的训练时间。在 $Tensorflow$ 中，我们可以直接调用高度抽象的函数 $batch\_normalization()$ 来实现。在试验中，$dropout$ 值的选择空间设定为： $[0.1,0.2,0.3,0.4,0.5]$， $l2$ 中的正则阈值选择空间设定为： $[3, 5,10,20,30,40, 50]$ 。

  \item \textit{$batch \;size$:} $batch \;size$ 的选择是一个需要权衡的考虑，没有固定的选择策略。在我们的模型中，选择设定 $batch \;size$ 为64。
\end{enumerate}

对于上面提到的参数，我们使用文章~\cite{zhang2015sensitivity}中相同的方法，通过较粗粒度的网格搜索($grid \; search$)来给模型选择一套合适的参数。具体的结果如表格~\ref{table:6}所示。

\begin{table}%[!hbp]
\centering
\topcaption{ CNN模型在不同数据集上的超参选择}
\label{table:6}
\begin{tabular}{|l|c|c|c|}
\hline
\diagbox{参数项}{参数值}{数据集} & 引文数据集 & 二手车 & 二手房 \\
\hline
卷积方式 & 宽卷积 & 宽卷积 & 宽卷积 \\ \hline
池化方式 & ${1-max \; Pooling}$ & ${1-max \; Pooling}$ & ${1-max \; Pooling}$ \\ \hline
激活函数 & $NoA$ & $Relu$ & $Relu$ \\ \hline
卷积核大小和数量 & ${(9,9)/200}$ & ${(10,10)/100}$ & ${(5,5)/400}$ \\ \hline
通道数 & 静态+动态 & 静态+动态 & 静态+动态 \\ \hline
正则化 & ${dropout:0.5, \; l2:20}$  & ${dropout:0.4,  \;l2:40}$ & ${dropout:0.4, \; l2:20}$ \\ \hline
\end{tabular}
\end{table}

\section{系统架构及展示}
为了方便执行抽取任务，方便将我们的方法移植到其他数据集，且可视化我们抽取模型的每一步结果，我们开发了一个在线训练模型和执行抽取的可视化系统。这个系统主要分为下面三个部分：

\vspace{-2pt}
\begin{enumerate}[1)]\setlength{\itemsep}{-1pt}
  \item \textit{模型初始化与模型训练}
    \begin{itemize}
        \item[*] 模型结构设计和参数设定：可以在网页上直接手动设计模型结构，比如指定通道个数，激活函数，卷积方式，Polling方式，指定超参的数值，比如指定规则化中Dropout值和l2的值，卷积核大小与数量等。如图~\ref{fig:model_set_train}(a)所示
        \item[*] 加载知识库（$Knowledge \; Base$），加载、预处理知识库中的各属性值。因为我们在构造CNN分类模型输入矩阵的时候，除了word2vec，我们还另外构造了五种特征，分别是word2vec，单词在文本段中的位置特征，单词在输入文本中的位置特征，文本段的长度，POS和归一化的类别概率，我们可以在系统上选择来只使用指定的几个特征。并且，因为我们在训练模型的时候，需要将输入特征向量化，因此还需要指定这些特征的维度，如图~\ref{fig:model_set_train}(b) 所示。
        选择性构造特征：手动选择数据预处理相关参数，选择要构造的特征，并预览训练数据的初始化结果等。
        \item[*] CNN分类模型训练过程可视化展现，这里我们直接通过iframe将TensorBoard投放到我们的系统中，我们可以直接查看系统的结构和模型训练的过程，然后通过观察loss的变化，当loss没有明显的变化时，我们提供‘提前停止’按钮，可以随时结束模型的训练。如图~\ref{fig:model_set_train}(c)所示
    \end{itemize}

  \item \textit{输入单条文本执行抽取任务}

   \begin{itemize}
        \item[*] 当需要每次抽取一条文本时，我们可以进入‘单条抽取’模块。加载对应的训练好的CNN分类模型，对应的知识库和抽取结果的存储文件，然后输入待抽取的一条文本，点击‘开始抽取’便可以开始执行抽取任务。因为本文提出的模型大体包括三个步骤，可以通过我们的系统观察每一步的结果。
        \item[*] 图~\ref{fig:one_record}(a)模块显示了基于知识库的初始分割和标注的结果，系统中将分割出来的文本段和相应的标签都显示出来，红色‘UN’表示基于知识库无法识别或者是得分没有达到指定阈值的文本段，有标签的文本段便是\emph{锚点块}。
        \item[*] 图~\ref{fig:one_record}(b)模块显示了通过使用本文提出的\emph{贪婪式概率标注算法}之后的结果，可以发现，大多数红色‘UN’的文本段都有了相应的标签，对于这个文本，还剩一个‘UN’的文本段。
        \item[*] 在图~\ref{fig:one_record}(c)中显示我们使用BPSM（双向位置与序列模型）对上面的结果进行修正，最终得到了正确的标注结果。
        \item[*] 图~\ref{fig:one_record}(d) 展示了目前学习到的BPSM，因为我们刚开始抽取这一条文本，可以看到这还是一个非常简单的BPSM模型。系统的实现中使用ECharts来展示出BPSM模型。然后点击‘存入文件’便可以将这条记录的抽取结果存入到结构化文本中，我们的系统可以根据选择的文本类型存储成不同的形式，包括xml 形式，json 形式和csv 格式。
    \end{itemize}

  \item \textit{输入一个文件(多条文本)执行抽取任务}
    \begin{itemize}
        \item[*] 为了提高抽取的效率，系统也支持多条文本一起抽取，就是读入一个文件。并显示抽取进度和提供暂停的按钮。跟抽取一条文本显示的内容一样，系统也显示三个步骤的中间结果，同时显示两条文本的抽取过程。图~\ref{fig:mul_record}(a)(b)(c)显示了目前这两条文本抽取的中间结果。图~\ref{fig:mul_record}(d)是我们执行了80\%的文本之后学习到的BPSM，发现比一开始的要复杂很多了。

    \end{itemize}
\end{enumerate}



\begin{figure}
  \centering
  \subfigure[设定模型参数]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.5in]{../figures/chap04/set_model_para.png}
  }
  \subfigure[加载知识库]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.5in]{../figures/chap04/load_kb.png}
  }
  \subfigure[训练模型]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.5in]{../figures/chap04/train_model.png}
  }
  \caption{模型初始化与训练}
  \label{fig:model_set_train} %% label for entire figure
\end{figure}


\begin{figure}
  \centering
  \subfigure[segment]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.4in]{../figures/chap04/segment-one.png}
  }
  \subfigure[cnn-label]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.5in]{../figures/chap04/cnn-label-one.png}
  }

  \subfigure[amendment]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.5in]{../figures/chap04/amendment-one.png}
  }
  \subfigure[BPSM]{
    %\label{fig:subfig:b} %% label for second subfigure
    \includegraphics[width=3.5in]{../figures/chap04/BPSM-one.png}
  }
  \caption{输入一条记录}
  \label{fig:one_record} %% label for entire figure
\end{figure}


\begin{figure}
  \centering
  \subfigure[segment]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.4in]{../figures/chap04/segment-mul.png}
  }
  \subfigure[cnn-label]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.4in]{../figures/chap04/cnn-label-mul.png}
  }

  \subfigure[amendment]{
    %\label{fig:subfig:a} %% label for first subfigure
    \includegraphics[width=3.4in]{../figures/chap04/amendment-mul.png}
  }
  \subfigure[BPSM]{
    %\label{fig:subfig:b} %% label for second subfigure
    \includegraphics[width=3.4in]{../figures/chap04/BPSM-mul.png}
  }
  \caption{输入一个文件}
  \label{fig:mul_record} %% label for entire figure
\end{figure}



\section{本章小结}
本章详细介绍了构造CNN分类模型的诸多细节，因为CNN分类模型很多超参的设定值没有一个固定的理论支持，并且是对数据集敏感的，所以，我们通过查阅文档，并在不同的数据集上做实验，得到了最适合我们的数据集的设计模式和超参的值。然后，本章介绍了我们开发的自动训练与执行抽取的系统，这个系统是对本文提出的算法的包装，同时添加了训练模型相关的模块。本章详细介绍了每个模块的内容并给出了演示的截图。

